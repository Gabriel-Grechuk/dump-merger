#! /usr/bin/node

const fs = require('fs');

const defaultHeader = `
--- File generated by dump-merger.
--- (https://github.com/Gabriel-Grechuk/dump-merger)

SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;


`;

// This is a Murmur Hash implementation by Gary Court under the MIT license.
// You can find the source here:
// (https://github.com/garycourt/murmurhash-js/blob/master/murmurhash3_gc.js)
function murmurhash3_32_gc(key) {
  let remainder, bytes, h1, h1b, c1, c2, k1, i;

  remainder = key.length & 3; // key.length % 4
  bytes = key.length - remainder;
  h1 = 42;
  c1 = 0xcc9e2d51;
  c2 = 0x1b873593;
  i = 0;

  while (i < bytes) {
    k1 =
      (key.charCodeAt(i) & 0xff) |
      ((key.charCodeAt(++i) & 0xff) << 8) |
      ((key.charCodeAt(++i) & 0xff) << 16) |
      ((key.charCodeAt(++i) & 0xff) << 24);
    ++i;

    k1 =
      ((k1 & 0xffff) * c1 + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;
    k1 = (k1 << 15) | (k1 >>> 17);
    k1 =
      ((k1 & 0xffff) * c2 + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;

    h1 ^= k1;
    h1 = (h1 << 13) | (h1 >>> 19);
    h1b =
      ((h1 & 0xffff) * 5 + ((((h1 >>> 16) * 5) & 0xffff) << 16)) & 0xffffffff;
    h1 = (h1b & 0xffff) + 0x6b64 + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16);
  }

  k1 = 0;

  switch (remainder) {
    case 3:
      k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;
    case 2:
      k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;
    case 1:
      k1 ^= key.charCodeAt(i) & 0xff;

      k1 =
        ((k1 & 0xffff) * c1 + ((((k1 >>> 16) * c1) & 0xffff) << 16)) &
        0xffffffff;
      k1 = (k1 << 15) | (k1 >>> 17);
      k1 =
        ((k1 & 0xffff) * c2 + ((((k1 >>> 16) * c2) & 0xffff) << 16)) &
        0xffffffff;
      h1 ^= k1;
  }

  h1 ^= key.length;

  h1 ^= h1 >>> 16;
  h1 =
    ((h1 & 0xffff) * 0x85ebca6b +
      ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) &
    0xffffffff;
  h1 ^= h1 >>> 13;
  h1 =
    ((h1 & 0xffff) * 0xc2b2ae35 +
      ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16)) &
    0xffffffff;
  h1 ^= h1 >>> 16;

  return h1 >>> 0;
}

function getFileFormat(str) {
  const regex = /\.[0-9a-z]+$/i;
  const match = regex.exec(str);
  return match ? match[0].substring(1).toLowerCase() : '';
}

function parseCommandArgs() {
  const filesPaths = [];

  for (const arg of process.argv.slice(2)) {
    const fileFormat = getFileFormat(arg);
    if (fileFormat === '' || fileFormat !== 'sql') {
      console.log(`ERROR: One of the arguments is not a sql file: ${arg}`);
      process.exit(1);
    }

    if (!fs.existsSync(arg)) {
      console.log(`ERROR: The file ${arg} does not exists.`);
      process.exit(1);
    }

    filesPaths.push(arg);
  }

  return filesPaths;
}

function parseCOPY(str) {
  const regex = /^COPY\s+(\w+\.\w+)\s+\(([^)]+)\)\s+FROM\s+\w+\s*;/;
  const match = str.match(regex);
  if (!match) return null;

  const table = match[1];
  const columns = match[2].split(',').map((col) => col.trim());

  return { table, columns };
}

function parseData(str) {
  return str.split('\t').map((col) => col.trim());
}

function parseFile(path) {
  const database = {};

  const content = fs
    .readFileSync(path, { encoding: 'utf8', flag: 'r' })
    .split('\n');

  let contentBlock = false;
  let tableBuffer = {};
  let tableName = '';
  for (const line of content) {
    if (line.includes('COPY')) {
      if (contentBlock === true) {
        Object.assign(database, tableBuffer);
        tableBuffer = {};
        tableName = '';
        contentBlock = false;
        continue;
      }

      contentBlock = true;
      const content = parseCOPY(line);
      if (!content) {
        console.log(`Error: Invalid COPY arg:\n${line}`);
        process.exit(1);
      }

      tableName = content.table;
      Object.assign(tableBuffer, {
        [content.table]: {
          columns: content.columns,
          content: [],
        },
      });
      continue;
    }

    if (line === '\\.') {
      Object.assign(database, tableBuffer);

      contentBlock = false;
      tableBuffer = {};
      tableName = '';
    }

    if (contentBlock) {
      const row = { hash: murmurhash3_32_gc(line), data: parseData(line) };
      tableBuffer[tableName]['content'].push(row);
    }
  }

  return database;
}

function merge(databases) {
  const mergedTable = {};

  for (const database of databases) {
    console.log(database);
    Object.keys(database).forEach((key) => {
      const insertedData = [];
      const table = database[key];

      Object.assign(mergedTable, {
        [key]: {
          columns: table.columns,
          content: [],
        },
      });

      const tables_to_ignore = ['public.zip_codes', 'public.districts'];

      if (tables_to_ignore.includes(key)) {
        mergedTable[key].content = table.content;
        return;
      }

      // If there is a ID column, it will be used to be used as the unique key.
      console.log(table.columns);
      if (table.columns.includes('id')) {
        for (const row of table.content) {
          if (!insertedData.includes(row.data[0])) {
            console.log(`(${key}): Inserting ${row.hash} data by id...`);
            mergedTable[key].content.push(row);
            insertedData.push(row.data[0]);
          } else {
            console.log(`(${key}): Ignoring duplicated ${row.data[0]}`);
          }
        }
      }

      // If there is no ID column, the hash will be used as unique key.
      // This prevents any-to-any tables to have all its data dropped because
      // most of it's columns have the same ID or value.
      else {
        for (const row of table.content) {
          if (!insertedData.includes(row.hash)) {
            console.log(`(${key}): Inserting ${row.hash} data by id...`);
            mergedTable[key].content.push(row);
            insertedData.push(row.hash);
          } else {
            console.log(`(${key}): Ignoring duplicated ${row.hash}`);
          }
        }
      }
    });
  }

  return mergedTable;
}

function writeSQL(database) {
  fs.writeFileSync('merged.sql', defaultHeader, { flag: 'w' });
  Object.keys(database).forEach((key) => {
    const table = database[key];
    const columnsStr = table.columns.join(', ');

    fs.writeFileSync(
      'merged.sql',
      `COPY ${key} (${columnsStr}) FROM stdin;\n`,
      { flag: 'a+' },
    );

    for (const row of table.content) {
      const rowStr = row.data.join('\t');
      fs.writeFileSync('merged.sql', `${rowStr}\n`, { flag: 'a+' });
    }

    fs.writeFileSync('merged.sql', '\\.\n\n\n', { flag: 'a+' });
  });
}

function main() {
  const files = parseCommandArgs();
  const data = files.map((file) => {
    console.log(`INFO: Loading "${file}", it may take a while...`);
    const res = parseFile(file);
    console.log(`INFO (${file}): Done!`);
    return res;
  });

  console.log('INFO: Merging dumps... It may also take a while...');
  const mergedTable = merge(data);
  console.log('INFO: Done Merging dumps...');
  console.log('INFO: Writing SQL file...');
  writeSQL(mergedTable);
  console.log('\n\nINFO: All Done!');
}

main();
